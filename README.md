## ðŸ§  WalkNav: YOLOv8-Based Assistive Navigation for the Visually Impaired

> **Empowering independent mobility using real-time path detection and audio guidance.**

---

### ðŸ“Œ Project Overview

**WalkNav** is a computer vision-based assistive navigation system designed to help visually impaired individuals navigate outdoor environments. It uses a **YOLOv8 segmentation model** to detect walkable paths in real-time and provides **audio feedback** to guide users safely and effectively.

---

### ðŸ› ï¸ Features

* âœ… Real-time walkable path detection using YOLOv8
* ðŸŽ¯ Accurate segmentation trained on a custom-labeled dataset
* ðŸŽ™ï¸ Audio feedback (e.g., â€œTurn Leftâ€, â€œMove Forwardâ€)
* ðŸ“· Live camera input processing
* ðŸ§© Modular design for future upgrades like GPS navigation

---

### ðŸ“‚ Project Structure

```plaintext
ASEP2/
â”œâ”€â”€ dataset/
â”‚   â”œâ”€â”€ images/                # Original images
â”‚   â”‚   â”œâ”€â”€ train/
â”‚   â”‚   â””â”€â”€ val/
â”‚   â””â”€â”€ labels/                # YOLO-format labels
â”‚       â”œâ”€â”€ train/
â”‚       â””â”€â”€ val/
â”œâ”€â”€ annotations/               # Original polygonal JSON annotations
â”œâ”€â”€ masks/                     # Masked-out images for segmentation
â”œâ”€â”€ convert_masks_to_yolo.py   # Script to convert JSON to YOLO format
â”œâ”€â”€ yolov8_train.py            # Model training script
â”œâ”€â”€ yolov8_infer.py            # Inference with real-time feedback
â””â”€â”€ README.md                  # You are here!
```

---

### ðŸš€ How It Works

1. **Custom dataset** of 2,800+ annotated outdoor images
2. Images annotated using polygons to define footpaths (stored as JSON)
3. Converted to YOLOv8 segmentation format
4. Model trained using Ultralytics' YOLOv8 on CPU/GPU
5. Inference script uses webcam + TTS to give spoken directions

---

### ðŸ§ª Model Performance

| Metric            | Score     |
| ----------------- | --------- |
| mAP\@0.5 (Mask)   | 0.94      |
| mAP\@0.5:0.95     | 0.79      |
| Precision (Mask)  | 0.94      |
| Recall (Mask)     | 0.87      |
| FPS (Live Camera) | 15â€“20 FPS |

---

### ðŸ—£ï¸ Audio Feedback

Real-time voice instructions:

* â€œMove Forwardâ€
* â€œTurn Leftâ€
* â€œObstacle Aheadâ€

Powered by Python's `pyttsx3` for text-to-speech.

---

### âš™ï¸ Tech Stack

* ðŸ Python 3.13
* ðŸ“¦ Ultralytics YOLOv8 (v8.3+)
* ðŸ“¸ OpenCV
* ðŸ”Š pyttsx3 (for voice feedback)
* ðŸ§  Custom annotation & training scripts

---

### ðŸ”§ Setup Instructions

```bash
git clone https://github.com/Sujay-Korde/WalkNav-YOLOSeg.git
cd WalkNav-YOLOSeg
pip install -r requirements.txt
```

---

### ðŸ§  Train the Model

```bash
python yolov8_train.py  # Ensure paths to dataset are configured
```

---

### ðŸ“¸ Run Live Inference

```bash
python yolov8_infer.py --weights runs/segment/train8/weights/best.pt
```

=======
## ðŸ“ˆ Future Scope

- GPS + Google Maps integration
- Multi-class segmentation (stairs, curbs, potholes)
- Vibration feedback for enhanced accessibility

---

## ðŸ‘¨â€ðŸ’» Contributors

- **Sujay Korde** â€“ 
- **Anish Kshirsagar**
- **Kritika Ingle**
- **Kimaya Kolhe**
- **Abhishek Kulkarni**

---

## ðŸ“œ License

This project is open-source and available under the [MIT License](LICENSE).
>>>>>>> 64c278e (Add README file with contributors)
