## ğŸ§  WalkNav: YOLOv8-Based Assistive Navigation for the Visually Impaired

> **Empowering independent mobility using real-time path detection and audio guidance.**

---

### ğŸ“Œ Project Overview

**WalkNav** is a computer vision-based assistive navigation system designed to help visually impaired individuals navigate outdoor environments. It uses a **YOLOv8 segmentation model** to detect walkable paths in real-time and provides **audio feedback** to guide users safely and effectively.

---

### ğŸ› ï¸ Features

* âœ… Real-time walkable path detection using YOLOv8
* ğŸ¯ Accurate segmentation trained on a custom-labeled dataset
* ğŸ™ï¸ Audio feedback (e.g., â€œTurn Leftâ€, â€œMove Forwardâ€)
* ğŸ“· Live camera input processing
* ğŸ§© Modular design for future upgrades like GPS navigation

---

### ğŸ“‚ Project Structure

```plaintext
ASEP2/
â”œâ”€â”€ dataset/
â”‚   â”œâ”€â”€ images/                # Original images
â”‚   â”‚   â”œâ”€â”€ train/
â”‚   â”‚   â””â”€â”€ val/
â”‚   â””â”€â”€ labels/                # YOLO-format labels
â”‚       â”œâ”€â”€ train/
â”‚       â””â”€â”€ val/
â”œâ”€â”€ annotations/               # Original polygonal JSON annotations
â”œâ”€â”€ masks/                     # Masked-out images for segmentation
â”œâ”€â”€ convert_masks_to_yolo.py   # Script to convert JSON to YOLO format
â”œâ”€â”€ yolov8_train.py            # Model training script
â”œâ”€â”€ yolov8_infer.py            # Inference with real-time feedback
â””â”€â”€ README.md                  # You are here!
```

---

### ğŸš€ How It Works

1. **Custom dataset** of 2,800+ annotated outdoor images
2. Images annotated using polygons to define footpaths (stored as JSON)
3. Converted to YOLOv8 segmentation format
4. Model trained using Ultralytics' YOLOv8 on CPU/GPU
5. Inference script uses webcam + TTS to give spoken directions

---

### ğŸ§ª Model Performance

| Metric            | Score     |
| ----------------- | --------- |
| mAP\@0.5 (Mask)   | 0.94      |
| mAP\@0.5:0.95     | 0.79      |
| Precision (Mask)  | 0.94      |
| Recall (Mask)     | 0.87      |
| FPS (Live Camera) | 15â€“20 FPS |

---

### ğŸ—£ï¸ Audio Feedback

Real-time voice instructions:

* â€œMove Forwardâ€
* â€œTurn Leftâ€
* â€œObstacle Aheadâ€

Powered by Python's `pyttsx3` for text-to-speech.

---

### âš™ï¸ Tech Stack

* ğŸ Python 3.13
* ğŸ“¦ Ultralytics YOLOv8 (v8.3+)
* ğŸ“¸ OpenCV
* ğŸ”Š pyttsx3 (for voice feedback)
* ğŸ§  Custom annotation & training scripts

---

### ğŸ”§ Setup Instructions

```bash
git clone https://github.com/Sujay-Korde/WalkNav-YOLOSeg.git
cd WalkNav-YOLOSeg
pip install -r requirements.txt
```

---

### ğŸ§  Train the Model

```bash
python yolov8_train.py  # Ensure paths to dataset are configured
```

---

### ğŸ“¸ Run Live Inference

```bash
python yolov8_infer.py --weights runs/segment/train8/weights/best.pt
```

---

### ğŸ“ˆ Future Scope

* GPS + Google Maps integration
* Multi-class segmentation (stairs, curbs, potholes)
* Vibration feedback for enhanced accessibility

---

### ğŸ‘¨â€ğŸ’» Contributors

* **Sujay Korde** â€“ Developer, Annotator, and Trainer

---

### ğŸ“œ License

This project is open-source and available under the [MIT License](LICENSE).

---


